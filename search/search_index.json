{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"YOLO3D: 3D Object Detection with YOLO \u00b6 \u26a0\ufe0f Cautions \u00b6 This repository currently under development \ud83d\udcfc Demo \u00b6 ![demo](./assets/demo.gif) \ud83d\udccc Introduction \u00b6 Unofficial implementation of Mousavian et al. in their paper 3D Bounding Box Estimation Using Deep Learning and Geometry . YOLO3D uses a different approach, as the detector uses YOLOv5 which previously used Faster-RCNN, and Regressor uses ResNet18/VGG11 which was previously VGG19. \ud83d\ude80 Quickstart \u00b6 We use hydra as the config manager; if you are unfamiliar with hydra, you can visit the official website or see the tutorial on this web. \ud83c\udf7f Inference \u00b6 You can use pretrained weight from Release , you can download it using script get_weights.py : # download pretrained model python script/get_weights.py \\ --tag v0.1 \\ --dir ./weights Inference with inference.py : python inference.py \\ source_dir = \"./data/demo/images\" \\ detector.model_path = \"./weights/detector_yolov5s.pt\" \\ regressor_weights = \"./weights/regressor_resnet18.pt\" \u2694\ufe0f Training \u00b6 There are two models that will be trained here: detector and regressor . For now, the detector model that can be used is only YOLOv5 , while the regressor model can use all models supported by Torchvision . \ud83e\udded Training YOLOv5 Detector \u00b6 The first step is to change the label_2 format from KITTI to YOLO. You can use the following src/kitti_to_yolo.py . cd yolo3d-lightning/src python kitti_to_yolo.py \\ --dataset_path ../data/KITTI/training/ --classes [ \"car\" , \"van\" , \"truck\" , \"pedestrian\" , \"cyclist\" ] --img_width 1224 --img_height 370 The next step is to follow the wiki provided by ultralytics . Note: readme will updated in future . \ud83e\ude80 Training Regessor \u00b6 Selanjutnya, kamu dapat melakukan training model regressor. Model regressor yang dapat dipakai bisa mengacu pada yang tersedia di torchvision , atau kamu bisa mengkustomnya sendiri. Langkah pertama adalah membuat train dan validation sets. Kamu dapat menggunakan script/generate_sets.py : cd yolo3d-lightning/script python generate_sets.py \\ --images_path ../data/KITTI/training/images # or image_2 --dump_dir ../data/KITTI/training --postfix _80 --train_size 0 .8 Pada langkah selanjutnya, kita hanya akan menggunakan model yang ada di torchvision saja. Langkah termudah adalah dengan mengubah configurasi di configs.model.regressor.yaml , seperti di bawah: _target_ : src.models.regressor.RegressorModel net : _target_ : src.models.components.base.RegressorNet backbone : _target_ : torchvision.models.resnet18 # edit this pretrained : True # maybe this too bins : 2 lr : 0.001 momentum : 0.9 w : 0.4 alpha : 0.6 Langkah selanjutnya adalah dengan membuat konfigurasi experiment pada configs/experiment/your_exp.yaml . Jika bingung, kamu dapat mengacu pada configs/experiment/demo.yaml . Setelah konfigurasi experiment dibuat. Kamu dapat dengan mudah menjalankan perintah train.py , seperti berikut: cd yolo3d-lightning python train.py \\ experiment = demo \u2764\ufe0f Acknowledgement \u00b6 YOLOv5 by Ultralytics skhadem/3D-BoundingBox Mousavian et al. @misc{mousavian20173d, title={3D Bounding Box Estimation Using Deep Learning and Geometry}, author={Arsalan Mousavian and Dragomir Anguelov and John Flynn and Jana Kosecka}, year={2017}, eprint={1612.00496}, archivePrefix={arXiv}, primaryClass={cs.CV} }","title":"Home"},{"location":"#yolo3d-3d-object-detection-with-yolo","text":"","title":"YOLO3D: 3D Object Detection with YOLO"},{"location":"#cautions","text":"This repository currently under development","title":"\u26a0\ufe0f&nbsp;&nbsp;Cautions"},{"location":"#demo","text":"![demo](./assets/demo.gif)","title":"\ud83d\udcfc&nbsp;&nbsp;Demo"},{"location":"#introduction","text":"Unofficial implementation of Mousavian et al. in their paper 3D Bounding Box Estimation Using Deep Learning and Geometry . YOLO3D uses a different approach, as the detector uses YOLOv5 which previously used Faster-RCNN, and Regressor uses ResNet18/VGG11 which was previously VGG19.","title":"\ud83d\udccc&nbsp;&nbsp;Introduction"},{"location":"#quickstart","text":"We use hydra as the config manager; if you are unfamiliar with hydra, you can visit the official website or see the tutorial on this web.","title":"\ud83d\ude80&nbsp;&nbsp;Quickstart"},{"location":"#inference","text":"You can use pretrained weight from Release , you can download it using script get_weights.py : # download pretrained model python script/get_weights.py \\ --tag v0.1 \\ --dir ./weights Inference with inference.py : python inference.py \\ source_dir = \"./data/demo/images\" \\ detector.model_path = \"./weights/detector_yolov5s.pt\" \\ regressor_weights = \"./weights/regressor_resnet18.pt\"","title":"\ud83c\udf7f&nbsp;&nbsp;Inference"},{"location":"#training","text":"There are two models that will be trained here: detector and regressor . For now, the detector model that can be used is only YOLOv5 , while the regressor model can use all models supported by Torchvision .","title":"\u2694\ufe0f&nbsp;&nbsp;Training"},{"location":"#training-yolov5-detector","text":"The first step is to change the label_2 format from KITTI to YOLO. You can use the following src/kitti_to_yolo.py . cd yolo3d-lightning/src python kitti_to_yolo.py \\ --dataset_path ../data/KITTI/training/ --classes [ \"car\" , \"van\" , \"truck\" , \"pedestrian\" , \"cyclist\" ] --img_width 1224 --img_height 370 The next step is to follow the wiki provided by ultralytics . Note: readme will updated in future .","title":"\ud83e\udded&nbsp;&nbsp;Training YOLOv5 Detector"},{"location":"#training-regessor","text":"Selanjutnya, kamu dapat melakukan training model regressor. Model regressor yang dapat dipakai bisa mengacu pada yang tersedia di torchvision , atau kamu bisa mengkustomnya sendiri. Langkah pertama adalah membuat train dan validation sets. Kamu dapat menggunakan script/generate_sets.py : cd yolo3d-lightning/script python generate_sets.py \\ --images_path ../data/KITTI/training/images # or image_2 --dump_dir ../data/KITTI/training --postfix _80 --train_size 0 .8 Pada langkah selanjutnya, kita hanya akan menggunakan model yang ada di torchvision saja. Langkah termudah adalah dengan mengubah configurasi di configs.model.regressor.yaml , seperti di bawah: _target_ : src.models.regressor.RegressorModel net : _target_ : src.models.components.base.RegressorNet backbone : _target_ : torchvision.models.resnet18 # edit this pretrained : True # maybe this too bins : 2 lr : 0.001 momentum : 0.9 w : 0.4 alpha : 0.6 Langkah selanjutnya adalah dengan membuat konfigurasi experiment pada configs/experiment/your_exp.yaml . Jika bingung, kamu dapat mengacu pada configs/experiment/demo.yaml . Setelah konfigurasi experiment dibuat. Kamu dapat dengan mudah menjalankan perintah train.py , seperti berikut: cd yolo3d-lightning python train.py \\ experiment = demo","title":"\ud83e\ude80&nbsp;&nbsp;Training Regessor"},{"location":"#acknowledgement","text":"YOLOv5 by Ultralytics skhadem/3D-BoundingBox Mousavian et al. @misc{mousavian20173d, title={3D Bounding Box Estimation Using Deep Learning and Geometry}, author={Arsalan Mousavian and Dragomir Anguelov and John Flynn and Jana Kosecka}, year={2017}, eprint={1612.00496}, archivePrefix={arXiv}, primaryClass={cs.CV} }","title":"\u2764\ufe0f&nbsp;&nbsp;Acknowledgement"},{"location":"command/","text":"Quick Command \u00b6 Train Regressor Model \u00b6 Train original python src/train.py With experiment python src/train.py \\ experiment = sample Train Detector Model \u00b6 Yolov5 \u00b6 Multi GPU Training cd yolov5 python -m torch.distributed.launch \\ --nproc_per_node 4 train.py \\ --epochs 10 \\ --batch 64 \\ --data ../configs/detector/yolov5_kitti.yaml \\ --weights yolov5s.pt \\ --device 0 ,1,2,3 Single GPU Training cd yolov5 python train.py \\ --data ../configs/detector/yolov5_kitti.yaml \\ --weights yolov5s.pt \\ --img 640 Hyperparameter Tuning with Hydra \u00b6 python src/train.py -m \\ hparams_search = regressor_optuna \\ experiment = sample_optuna","title":"Quick Command"},{"location":"command/#quick-command","text":"","title":"Quick Command"},{"location":"command/#train-regressor-model","text":"Train original python src/train.py With experiment python src/train.py \\ experiment = sample","title":"Train Regressor Model"},{"location":"command/#train-detector-model","text":"","title":"Train Detector Model"},{"location":"command/#yolov5","text":"Multi GPU Training cd yolov5 python -m torch.distributed.launch \\ --nproc_per_node 4 train.py \\ --epochs 10 \\ --batch 64 \\ --data ../configs/detector/yolov5_kitti.yaml \\ --weights yolov5s.pt \\ --device 0 ,1,2,3 Single GPU Training cd yolov5 python train.py \\ --data ../configs/detector/yolov5_kitti.yaml \\ --weights yolov5s.pt \\ --img 640","title":"Yolov5"},{"location":"command/#hyperparameter-tuning-with-hydra","text":"python src/train.py -m \\ hparams_search = regressor_optuna \\ experiment = sample_optuna","title":"Hyperparameter Tuning with Hydra"}]}